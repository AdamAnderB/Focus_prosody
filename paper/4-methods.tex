\section{Methods}
Experimental materials, unidentifiable data, and R code are openly available through the 
\href{https://osf.io/wa4gv/?view_only=de113dbced6b46fab96ca8217b3c1ca6}{Open Science Framework}.


\subsection{Participants}
A total of 130 participants were initially recruited for the study. We recruited participants according to their first language (L1), which we defined as the language acquired from birth and the language that the speaker considered most fluent. We defined the L2 as the language acquired in childhood after the L1 was in place and the language that the speaker considers less fluent than their L1. Unlike \textcite{ge2021a}, which recruited L1 English participants from study abroad students population in Hong Kong, our L1 English participants were recruited via Prolific (N = 25) \parencite{prolific2024} or in-person at a North American university (N = 50). All L1 English participants reported being born in the United States. The L1 Dutch-L2 English speakers (N = 55) were fully recruited via Prolific and all reported being born in the Netherlands. To ensure consistency, participants completed a detailed language background questionnaire \parencite{Marian_Blumenfeld_Kaushanskaya_2007}, confirming their age of L2 acquisition, language exposure history, and self-rated proficiency. No participants had significant early exposure to other languages at home, and all participants completed primary and secondary education in English or Dutch-speaking environments, respectively. From these 130 participants, we required that all participants provide informed consent, pass a basic hearing screening using a dichotic pitch task \parencite{milne_2021}, and pass a 5-point eye-tracking calibration with sufficient lighting. This left a total of 105 participants (L1 English N = 74; L1 Dutch N = 31) who qualified and completed the study. These participants were compensated for their time. To ensure that participants were engaged in the online tasks, we further specified that participants scored within 3 median absolute deviations (MADs) \parencite{Leys_2013} for all behavioral tasks. After removal, this left 61 L1 English speakers and 27 L1 Dutch speakers. All participants provided informed consent in accordance with IRB-approved procedures and were compensated for their time and effort.

\textcite{ge2021a} \hl{recruited university students in lab settings in the Netherlands (L1 Dutch–L2 English) and Hong Kong (L1 Cantonese–L2 English). Our participants were recruited online via Prolific and completed the study remotely. This broadened the demographic profile of both L1 and L2 groups but also introduced more heterogeneity in testing environments. We view this as an implementation-level adaptation of recruitment, not a design-level methodological change.}

\subsection{Materials}
All materials used in the present study were freely available and taken from previously published research (for which we are very grateful). The forward digit span task, Flanker task, and LexTALE \parencite{lemhofer2012introducing} were taken from the Gorilla \parencite{Anwyl-Irvine_2019} Open Materials repository (see our OSF page for more details). The perceptual auditory sensitivity and auditory motor reproduction tasks were provided by \textcite{Kachlicka_Saito_Tierney_2019, saito2020domain}. Auditory and visual stimuli for the eye-tracking task were provided by \textcite{ge2021a}. While \textcite{ge2021a} did not conduct an independent acoustic analysis, we used  Parselmouth \parencite{jadoul2018introducing} and the R `reticulate' package \parencite{Ushey2022} we extracted acoustic measures from \textcite{ge2021a}'s stimuli. This yielded four normalized key parameters: pitch range (min-max pitch per word), amplitude (measured in dB), duration, and word stress (measured as spectral tilt in lower frequencies). All scaled values can be seen in Figure \ref{fig:acoustic_faceted}.

\begin{figure}[H]  % 'p' puts it on its own page
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{viz/acoustic_faceted.png}
    \caption{Scaled duration, fundamental frequency (pitch) range, stress prominence, and amplitude by time word for object-focused (blue) and verb-focused (orange) sentences.}
    \label{fig:acoustic_faceted}
\end{figure}


\subsection{Procedure}

The experiment was hosted on Gorilla \parencite{Anwyl-Irvine_2019} and distributed via Prolific, with participants completing the study on a personal computer in an environment that met the experiment’s requirements, such as adequate lighting and minimal background noise. Participants started with the first three tasks in a fixed order: digit span, auditory sensitivity, and Flanker. The digit span task began with two digits, each on screen for 500 ms, followed by a fixation cross for 250 ms. Participants were required to use their mouse to click a visual number pad and enter the same digits in the same order. The adaptive, forward task increased by one digit after each correct response and decreased by one digit after each incorrect response. The task contained 13 trials and took approximately two minutes to complete. The internal consistency of the items as measured by Cronbach's alpha was .63. 

The auditory sensitivity task included four same/different (AX) discrimination tasks across four cues:  pitch, risetime (the speed at which a sound reaches its peak amplitude), duration, and formant contrasts. Each task consisted of 36 trials in which a sound was played, followed by a 250 ms fixation cross, and then a second sound. Participants responded by pressing the ‘Z’ or ‘M’ key to indicate whether the sounds were the same or different. Each task used a continuum of 50 stimuli taken from \textcite{Kachlicka_Saito_Tierney_2019}, with 10 stimuli selected at varying distances (e.g., 10 Hz or 15 Hz for pitch). The order of stimulus distances and same/different trials was randomized. Each battery task took approximately 90 seconds to complete. The internal consistency of these tasks, measured by Cronbach’s alpha, was pitch = .75, risetime = .76, duration = .60, formants = .70. We note that both the auditory sensitivity and digit span tasks contained items of varying difficulty. For example, recalling two digits is inherently easier than recalling nine digits; discriminating between two sounds with a 50 Hz difference is easier than discriminating between two sounds with a 5 Hz difference. Given this variability, lower internal reliability, as measured by \textcite{Cronbach1951}, is expected. 

The Flanker task showed five arrows with the center arrow facing either the same (congruent) direction as the other four arrows or the opposite (incongruent) direction. Participants were asked to use their keyboard and press ‘Z’ if the middle arrow was facing left and ‘M’ if it was facing right. There were 12 practice trials with feedback followed by 96 trials without feedback (48 congruent; 48 incongruent) spread over four blocks of 24 trials each. After each trial, a fixation cross with varying timing was shown ranging from 400 to 1,000 ms. The internal consistency of the items measured by Cronbach’s alpha was .93.

Next, the eye-tracking task and the auditory-motor tasks were counterbalanced across participants to mitigate order effects and minimize potential biases related to task sequencing. For the eye-tracking task, gaze data were recorded using WebGazer.js \parencite{Papoutsaki}, implemented within Gorilla \parencite{Anwyl-Irvine_2019}, which is the only \hl{implementation level} difference between our task and \textcite{ge2021a}. Participants began with four practice trials followed by 44 experimental trials (20 target and 24 filler). The same two counterbalanced lists used in \textcite{ge2021a} were used for the present study. In each trial, the 2x2 visual display and auditory stimulus were presented simultaneously followed by 1,000 ms of silence. These auditory stimuli were recorded at 44.1 kHz (16-bit resolution, mono) by a male native speaker of British English. Forty target sentences contained \textit{only} with prosodic prominence on either the verb or the object, creating two experimental conditions: object-focus and verb-focus. An additional 48 fillers were created without the \textit{only} focus particle. Like the targets, these fillers contained a \textit{not}-fragment as in “The rabbit is licking the CANDY, not licking the ice cream.” Figure \ref{fig:sampleslide} shows an example of a 2x2 visual stimulus. Each stimulus consisted of a target (e.g., the rabbit licking the candy), a competitor corresponding to the object alternative focus (e.g., the rabbit licking the ice cream), a competitor corresponding to the verb alternative focus (e.g., the rabbit throwing the candy) and a distractor (e.g., the rabbit throwing the ice cream). The non-target items were structured to ensure balanced looks across visual stimuli so that participants could not infer the target-competitor pairing by visual inspection alone. Participants were told to simply look at the visual display and listen to the audio. After each trial, a 1,000 ms slide with a different cartoon character at the center of the screen was shown before advancing to the next trial. No feedback was given during the task. The eye-tracking task took approximately 15 minutes to complete.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{viz/Fig1-Geetal.jpg}
    \caption{Example 2x2 visual display taken from \textcite{ge2021a}.}
    \label{fig:sampleslide}
\end{figure}


The auditory-motor tasks consisted of two components: auditory-motor rhythm and auditory-motor melody, both adapted from \textcite{Kachlicka_Saito_Tierney_2019}. In the auditory-motor rhythm task, participants heard a rhythmic sequence consisting of 13 possible beat positions, played three times. They were then required to replicate the rhythm by pressing the space bar at the correct intervals. Each key press was time-stamped, and accuracy was assessed based on whether a beat was present (1) or absent (0). In the auditory-motor melody task, participants listened to a seven-note melody and were required to reproduce it using on-screen buttons corresponding to relative pitch levels. To maintain consistency, all melodies began with the middle pitch, ensuring a stable reference point for participants. Accuracy was determined by comparing the selected pitch to the correct response. The internal consistency of the items as measured by Cronbach's alpha was .92 for the melody task and .88 for the rhythm task.

After completing the eye-tracking task and auditory-motor tasks, the participants completed a modified version of the English LexTALE task \parencite{lemhofer2012introducing}. On each trial, participants were shown a fixation cross for 500 ms followed by a string of letters presented for 2000 ms. Participants used the ‘J’ and ‘K’ keys to indicate whether the displayed string was a real word or a non-word, within the given time limit. A total of 60 trials were completed, consisting of 40 words and 20 non-words presented in a randomized order. The internal consistency for the LexTALE task, measured by Cronbach’s alpha, was .92. The English LexTALE and was adapted from publicly available Gorilla open materials; while the original versions of LexTALE did not impose time limits, our version required responses within 2000 ms. The task took approximately three minutes to complete. After completing the LexTALE, participants were asked to complete a language questionnaire that detailed their language experience \parencite{Marian_Blumenfeld_Kaushanskaya_2007}. 


\subsection{Data analysis}

Analyses were carried out in R (version 4.4.3; \cite{R}) with a 0.05 alpha level for all null hypothesis significance tests. The individual difference measures were calculated so that each participant had a single score for each task. Working memory capacity, assessed using the forward digit span task, was determined by averaging the correctly recalled sequence lengths for each participant. One participant was removed for low performance in this task (outside 3 MAD). For the four auditory sensitivity tasks, all reaction times below 200 ms were removed across the four battery tasks. Following this, hits and false-alarms for each trial were scored and sensitivity to each contrast type (pitch, duration, formants, risetime) was then calculated using d-prime, a measure of sensitivity that accounts for bias. For all d$'$ calculated measures a constant of .05 was added to both hits/false-alarms with a Haldane correction/log-linear correction for values of 0 or 1 \parencite{Hautus1995}. One participant was removed for low performance in these tasks (outside 3 MAD).

The Flanker task was analyzed using drift rate estimates from a drift diffusion model (DDM) implemented in the brms package \parencite{burkner2017brms}. Reaction times were first filtered to remove extreme responses below 200 ms (anticipatory responses) and above 1750 ms (slow, inattentive responses). Trials were categorized as congruent (flankers match the target) or incongruent (flankers mismatch the target), and reaction time distributions were analyzed separately for each condition. A hierarchical Bayesian DDM was fit to the data using brms, with reaction time as the dependent variable and accuracy as the decision variable. Individual drift rate estimates were extracted for each participant from the model’s random effects structure. These values were used as the final measure of cognitive control, aligning with previous work that treats drift rate as a sensitivity index for attentional selection in Flanker tasks \parencite{poole2024putting}. 

For both auditory motor tasks, scores were computed so that each participant had a single score for each task. In the melody task, each individual note in a trial was scored as 1 for correct and 0 for incorrect, and these values were averaged within each trial to obtain a trial-level accuracy score. The final Melody Score was then calculated as the mean trial accuracy across all trials.  In the rhythm task, each individual beat within a trial was also scored as 1 for correct and 0 for incorrect, with these values averaged within each trial to determine trial accuracy. Reaction times were normalized by subtracting an initial offset to align responses with the expected rhythmic structure. Trials in which participants produced double beats (multiple key presses within a single beat position) were adjusted by retaining only the first response. The final Rhythm Score was calculated as the mean trial accuracy across all trials. Three participants were removed for low performance (outside 3 MAD).

For eye-tracking data removal, eye-fixations outside the possible screen area were removed. As suggested in \textcite{AOW}, quadrants were defined by the origin to maximize signal retention. Fixations at the beginning of the trials were normally distributed from the center along both the x and y axes. Eye-fixations with face confirmation below 100\% certainty were removed. We retained approximately 77.79\% of eye-fixations. Our data removal is slightly higher the other recent web-based eye-tracking studies. because the task is a look-and-listen task and we had no other way to ensure that participants were attending to the task. We set a minimal frame rate for participants to 5 fps \parencite{Vos_2022} and only five participants were removed for poor data quality. \hl{See supplemental materials for detailed range across participants variable frame rates.}

Like acoustic sensitivity measures, the scores for LexTALE exclude responses with RTs below 200 ms. While LexTALE is most commonly calculated by averaging the accuracy of non-words and words to control for bias \parencite{lemhofer2012introducing}, we calculated LexTALE scores by using d$'$ after ignoring non-responses, which also controls for bias by using the difference between z-scored hits and false-alarms. For all d$'$ calculated, a constant of .05 was added to both hits/false-alarms with a Haldane (log linear) correction for values of 0 \parencite{Hautus1995}. 

For the Language Background Questionnaire, participants' first language and most fluent or dominant language was used to confirm their L1 status. Interestingly, 11 participants had language experience that mismatched their Prolific designation (e.g., their primary language they provided in our questionnaire did not match what they self-categorized within Prolific). However, the mismatch was not randomly distributed. Of the 11 participants that had mismatched language background information, 10 came from the English group and one from the Dutch group. The one Dutch speaker self-reported that English being their dominant language even though their L1 is Dutch. These participants were removed from further analyses.

\hl{Following replication reporting guidelines }\parencite{mcmanus2024}, we
summarize in Table~\ref{tab:modifications} the differences between our study and \textcite{ge2021a}. \hl{We distinguish here between design-level changes, which are intentional experimental manipulations, and implementation-level adaptations, which are pragmatic accommodations made to reproduce a study as faithfully as possible with available tools. In our case, the contrasts largely reflect implementation-level adaptations associated with online testing, not design-level methodological changes. Analytical refinements and extensions were then layered on top of this replication.}

\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Domain} & \textbf{Ge et al. (2021a)} & \textbf{This Study} \\
        \hline
        Participants & L1 English (HK), L1 Dutch, L1 Cantonese & L1 English (US), L1 Dutch; no Cantonese \\
        \hline
        Recruitment & In-lab & Online (Prolific + US university) \\
        \hline
        Modality & Tobii eye-tracker (lab) & WebGazer.js (webcam) \\
        \hline
        Stimuli & Original only-sentence materials & Same stimuli; added acoustic analysis \\
        \hline
        Analysis & Time-binned LMMs & LMMs + GAMs + LASSO-GAMs \\
        \hline
    \end{tabular}
    }
    \caption{Key differences between Ge et al. (2021a) and the present replication.}
    \label{tab:modifications}
\end{table}